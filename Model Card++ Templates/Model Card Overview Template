# [Insert Name Here] Overview

## Description: <br>
[Describe what this algorithm/model does in one sentence, including supporting image/video and/or reference blog/article as available.  For instance, _______ [insert name of model] _______ [insert verb] _______.]

[This model is ready for commercial/non-commercial use.] OR [This model is for research and development only.] OR [This model is for demonstration purposes and not for production usage.]  <br>

## Third-Party Community Consideration [(Insert  for Non-NVIDIA Third-Party Community Models)] <br>
This model is not owned or developed by NVIDIA. This model has been developed and built to a third-partyâ€™s requirements for this application and use case; see link to Non-NVIDIA [(Insert Name) Model Card](Insert Link).

### License/Terms of Use: <br> 
[Visit the NVIDIA Legal Release Process](https://nvidia.sharepoint.com/sites/ProductLegalSupport) for instructions on getting legal support for a license selection:

-If you are releasing under an open source license (such as Apache 2.0, MIT), contact the [Open Source Review Board](https://confluence.nvidia.com/pages/viewpage.action?pageId=800720661) (formerly SWIPAT) by filing a contribution bug request [here](https://nvbugspro.nvidia.com/bug/2885991).

-If your release is for non-commercial or research purposes only, file a new bug [here](https://nvbugspro.nvidia.com/bug/3508089).

-If your release allows for commercial purposes, submit [Product Legal Support Form](https://forms.office.com/pages/responsepage.aspx?id=FT0IQ3NywUC32znv2czBejILt4CYhTJKv0O6I4gccylUMVlMSE4xSFhYMUYyT1VMNVNCREk4RlE1NS4u&route=shorturl).

### Deployment Geography:
[Insert Global; Asia-Pacific (APAC); Europe, Middle East, and Africa (EMEA); Latin America (LATAM), North America (NAM), and/or specific countries]

### Use Case: <br>
[Answer who would be expected to use this system and for what] <br>

### Release Date:  <br>
[Insert MM/DD/YYY] <br>

## Reference(s) (Leave Blank If None):
[Provide list of reference(s), link(s) to the publication/paper/article, associated works, and lineage where relevant.]  <br> 

## Model Architecture: <br> 
**Architecture Type:** [Classify the architecture of the neural network if applicable (Convolution Neural Network (CNN), Recurrent Neural Network (RNN), or List Something Else]  <br>
**Network Architecture:** [(DarkNet19, DarkNet53, DetectNetv2, GoogleNet, MobileNet_v1, MobileNetv2, NvHelnet10, NvHelnet18, ResNet10, ResNet18, ResNet34, ResNet34, ResNet50, SqueezeNet, UNET, Vegg16, Vegg19, VGG10, or List Something Else] <br>

## Input: (Enter "None" As Needed) <br>
**Input Type(s):** [Audio, Image, Text, Tabular, etcetera (etc.)] <br>
**Input Format(s):** [Red, Green, Blue (RGB), Infrared (IR), Lidar, or String] <br>
**Input Parameters:** [(2D, 3D)] <br>
**Other Properties Related to Input:** [Specific Resolution/Minimum or Maximum Resolution, Characters (Including Restrictions), or Tokens;  Image Range Needed (W x Y x Z), Pre-Processing Needed, Alpha Channel, Bit; If None Applicable, Please State Such] <br>

## Output: (Enter "None" As Needed) <br>
**Output Type(s):** [Audio, Image, Text, Tabular, etc.] <br>
**Output Format:** [Red, Green, Blue (RGB), Infrared (IR), Lidar, or String] <br>
**Output Parameters:** [(2D, 3D)] <br>
**Other Properties Related to Output:** [Specific Resolution/Minimum or Maximum Resolution or Characters (Including Restrictions), or Tokens; Image Range (W x Y x Z), Post-Processing Needed, Alpha Channel, Bit; If None Applicable, Please State Such] <br> 

## Software Integration (Required For NVIDIA Models Only): <br>
**Runtime Engine(s):** <br>
* [BioNeMo- Name Mininimally Compatible Version] <br>
* [DeepStream- Name Mininimally Compatible Version] <br>
* [DXIS- Name Mininimally Compatible Version] <br>
* [Maxine- Name Mininimally Compatible Version] <br>
* [Morpheus- Name Mininimally Compatible Version] <br>
* [NeMo- Name Mininimally Compatible Version] <br>
* [Riva- Name Minimally Compatible Version] <br>
* [TAO- Name Minimally Compatible Version] <br>
* [Not Applicable (N/A)- Name Platform If Multiple] <br> 

**Supported Hardware Microarchitecture Compatibility:** <br>
* [NVIDIA Ampere or specific models] <br>
* [NVIDIA Blackwell or specific models] <br>
* [NVIDIA Jetson or specific models]  <br>
* [NVIDIA Hopper or specific models] <br>
* [NVIDIA Lovelace or specific models] <br>
* [NVIDIA Pascal or specific models] <br>
* [NVIDIA Turing or specific models] <br>
* [NVIDIA Volta or specific models] <br>
* [Insert NVIDIA Microarchitecture Name Not Listed Above] <br>

**[Preferred/Supported] Operating System(s):** <br>
* [Linux] <br>
* [Linux 4 Tegra] <br>
* [QNX]  <br>
* [Windows] <br>
* [Name Other Not Listed Above] <br>

## Model Version(s): 
[Use unique identifier for identifying the model in the future- this may be part of our internal naming, specifying variation like "pruned," "unpruned," "trained," or "deployable" or "quantized" where necessary and including a versioning number like vX.X along with short description differentiating if multiple versions are available]  <br>

# Training, Testing, and Evaluation Datasets: 

## Training Dataset [The dataset the model was trained on]:

**Link:** [Link or name to dataset used for training the model.  Share nSpect IDs.  nSpect IDs will be internal-only]  <br>
** Data Collection Method by dataset <br>
* [Automated] <br>
* [Automatic/Sensors] <br>
* [Human] <br>
* [Synthetic] <br>
* [Undisclosed] <br>
* [Hybrid: _______, _______] <br>
* [Not Applicable] <br>
** Labeling Method by dataset <br>
* [Automated] <br>
* [Automatic/Sensors] <br>
* [Human] <br>
* [Synthetic] <br>
* [Undisclosed] <br>
* [Hybrid: _______, _______] <br>
* [Not Applicable] <br>
**Properties (Quantity, Dataset Descriptions, Sensor(s)):** [Number of data items in training set, Descriptive Information about the data, If applicable, what specific sensor type was used for Data Collection] <br>
**Dataset License(s):** [Name, Link applicable to dataset license or applicable Jira ticket or NVBug. Write none if not applicable (N/A). This is an internal-only field.] <br>

## Testing Dataset [Typically, a subset of the training dataset that affirms the model is  performing as expected]:
**Link:** [Link or name to dataset used for training the model.  Share nSpect IDs.  nSpect IDs will be internal-only]  <br>
** Data Collection Method by dataset <br>
* [Automated] <br>
* [Automatic/Sensors] <br>
* [Human] <br>
* [Synthetic] <br>
* [Undisclosed] <br>
* [Hybrid: _______, _______] <br>
* [Not Applicable] <br>
** Labeling Method by dataset <br>
* [Automated] <br>
* [Automatic/Sensors] <br>
* [Human] <br>
* [Synthetic] <br>
* [Undisclosed] <br>
* [Hybrid: _______, _______] <br>
* [Not Applicable] <br>
**Properties (Quantity, Dataset Descriptions, Sensor(s)):** [Number of data items in training set, Descriptive Information about the data, If applicable, what specific sensor type was used for Data Collection] <br>
**Dataset License(s):** [Name, Link applicable to dataset license or applicable Jira ticket or NVBug. Write none if not applicable (N/A). This is an internal-only field.] <br>

## Evaluation Dataset [Dataset used to formally evaluate the model apart from the training dataset]:
**Link:** [Link or name to dataset used for evaluating the model.  Share nSpect IDs.  nSpect IDs will be internal-only]  <br>
** Data Collection Method by dataset <br>
* [Automated] <br>
* [Automatic/Sensors] <br>
* [Human] <br>
* [Synthetic] <br>
* [Undisclosed] <br>
* [Hybrid: _______, _______] <br>
* [Not Applicable] <br>
** Labeling Method by dataset <br>
* [Automated] <br>
* [Automatic/Sensors] <br>
* [Human] <br>
* [Synthetic] <br>
* [Undisclosed] <br>
* [Hybrid: _______, _______] <br>
* [Not Applicable] <br>
**Properties (Quantity, Dataset Descriptions, Sensor(s)):** [Number of data items in training set, Descriptive Information about the data, If applicable, what specific sensor type was used for Data Collection] <br>
**Dataset License(s):** [Name, Link applicable to dataset license or applicable Jira ticket or NVBug. Write none if not applicable (N/A). This is an internal-only field.] <br>

*Insert Key Performance Indicators or Evaluation Benchmarks Here (Reference https://docs.google.com/spreadsheets/d/1SwyHhBTFQJTLZ4tuc-JdDcjA7wy68DyWdTehGNUgJ6M/edit?gid=721511647#gid=721511647 for large language models)

## Inference:
**Engine:** [Tensor(RT), Triton, Or List Other Here] <br>
**Test Hardware [Name the specific test hardware model]:** <br>
* [Jetson XXNN] <br>
* [Drive X.X] <br>
* [List Other Here X.X]  <br>

*Additional content may be included here

## Ethical Considerations:
NVIDIA believes Trustworthy AI is a shared responsibility and we have established policies and practices to enable development for a wide array of AI applications.  When downloaded or used in accordance with our terms of service, developers should work with their internal model team to ensure this model meets requirements for the relevant industry and use case and addresses unforeseen product misuse.  

(For NVIDIA Commercial Models Only) For more detailed information on ethical considerations for this model, please see the Model Card++ Explainability, Bias, Safety & Security, and Privacy Subcards [Insert Link to Model Card++ here].  

(For Release on NVIDIA Platforms Only)
Please report security vulnerabilities or NVIDIA AI Concerns [here](https://www.nvidia.com/en-us/support/submit-security-vulnerability/).

**If anything is meant for internal-purposes only (including this statement and pre-filled content recommendations, please alert Trustworthy AI Product Manager or designee before publishing)

***You may remove "[]s" before publishing.  
